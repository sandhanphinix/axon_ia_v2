{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Axon IA: Inference\n",
    "\n",
    "This notebook demonstrates how to use Axon IA for inference on medical images. We'll cover:\n",
    "\n",
    "1. Loading a pre-trained model\n",
    "2. Setting up the inference predictor\n",
    "3. Running inference on a single image\n",
    "4. Processing a directory of images\n",
    "5. Visualizing and analyzing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up Environment and Load Model\n",
    "\n",
    "First, let's load a pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axon_ia.models import create_model\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define model parameters\n",
    "model_config = {\n",
    "    \"architecture\": \"unetr\",\n",
    "    \"in_channels\": 4,\n",
    "    \"out_channels\": 1,\n",
    "    \"img_size\": (128, 128, 128),\n",
    "    \"feature_size\": 8,  # Small feature size for this example\n",
    "    \"hidden_size\": 128  # Small hidden size for this example\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = create_model(**model_config)\n",
    "\n",
    "# Check for previously trained model checkpoint\n",
    "checkpoint_path = Path(\"../outputs/example_training/checkpoints/best_model.pth\")\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    # Load checkpoint\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    \n",
    "    # Check if checkpoint has state_dict directly or nested\n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}. Using untrained model.\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Inference Predictor\n",
    "\n",
    "Now, let's create the inference predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axon_ia.inference import Predictor\n",
    "\n",
    "# Configure predictor\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    sliding_window_size=(64, 64, 32),  # Smaller window size for this example\n",
    "    sliding_window_overlap=0.5,\n",
    "    sw_batch_size=2,\n",
    "    use_test_time_augmentation=False,  # Disable TTA for faster inference in this example\n",
    "    postprocessing_params={\n",
    "        \"threshold\": 0.5,\n",
    "        \"remove_small_objects\": True,\n",
    "        \"min_size\": 100,\n",
    "        \"fill_holes\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Test Data\n",
    "\n",
    "Let's create a synthetic test image for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic volume with a spherical \"lesion\"\n",
    "def create_synthetic_volume(size=(128, 128, 64), with_lesion=True):\n",
    "    # Create multi-modal data (4 channels)\n",
    "    volume = np.zeros((4, *size), dtype=np.float32)\n",
    "    \n",
    "    # Fill with random values for each modality\n",
    "    for i in range(4):\n",
    "        volume[i] = np.random.normal(100, 20, size).astype(np.float32)\n",
    "    \n",
    "    # Create a spherical region with higher intensity if requested\n",
    "    if with_lesion:\n",
    "        x, y, z = np.ogrid[:size[0], :size[1], :size[2]]\n",
    "        center_x, center_y, center_z = size[0]//2, size[1]//2, size[2]//2\n",
    "        sphere = ((x - center_x)**2 + (y - center_y)**2 + ((z - center_z))**2) <= (size[0]//8)**2\n",
    "        \n",
    "        # Add lesion to each modality with different contrast\n",
    "        volume[0][sphere] += 80  # FLAIR: hyperintense\n",
    "        volume[1][sphere] -= 20  # T1: hypointense\n",
    "        volume[2][sphere] += 50  # T2: hyperintense\n",
    "        volume[3][sphere] -= 30  # DWI: hypointense\n",
    "    \n",
    "    # Create ground truth mask\n",
    "    if with_lesion:\n",
    "        mask = sphere.astype(np.float32)\n",
    "    else:\n",
    "        mask = np.zeros(size, dtype=np.float32)\n",
    "    \n",
    "    return volume, mask\n",
    "\n",
    "# Create test volumes\n",
    "test_volume_with_lesion, test_mask_with_lesion = create_synthetic_volume(with_lesion=True)\n",
    "test_volume_without_lesion, test_mask_without_lesion = create_synthetic_volume(with_lesion=False)\n",
    "\n",
    "# Visualize\n",
    "from axon_ia.utils