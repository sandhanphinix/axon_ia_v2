{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffced86e",
   "metadata": {},
   "source": [
    "# Post-Training Model Analysis\n",
    "\n",
    "This notebook provides interactive analysis of your trained SwinUNETR model.\n",
    "Use this for detailed examination of model performance and planning improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f61f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd()))\n",
    "\n",
    "from axon_ia.config import ConfigParser\n",
    "from axon_ia.data import AxonDataset\n",
    "from axon_ia.models import create_model\n",
    "from axon_ia.evaluation.metrics import compute_metrics\n",
    "from axon_ia.utils.nifti_utils import load_nifti\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40dd99",
   "metadata": {},
   "source": [
    "## 1. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ce2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths based on your training results\n",
    "CONFIG_PATH = \"configs/training/swinunetr_config.yaml\"\n",
    "CHECKPOINT_PATH = \"/path/to/your/best_model.pth\"  # Update this!\n",
    "METRICS_FILE = \"/path/to/evaluation/metrics.json\"  # Update this!\n",
    "DATA_DIR = \"C:/development/data/axon_ia/processed\"  # Update if different\n",
    "\n",
    "# Load configuration\n",
    "config = ConfigParser(CONFIG_PATH)\n",
    "print(f\"Loaded config from: {CONFIG_PATH}\")\n",
    "print(f\"Model architecture: {config.get('model.architecture')}\")\n",
    "print(f\"Data directory: {config.get('data.root_dir')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71806887",
   "metadata": {},
   "source": [
    "## 2. Load and Analyze Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics (run evaluation script first if this file doesn't exist)\n",
    "try:\n",
    "    with open(METRICS_FILE, 'r') as f:\n",
    "        metrics_data = json.load(f)\n",
    "    \n",
    "    print(\"Overall Metrics:\")\n",
    "    for metric, value in metrics_data['overall'].items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    per_patient_df = pd.DataFrame(metrics_data['per_patient']).T\n",
    "    print(f\"\\nLoaded metrics for {len(per_patient_df)} patients\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Metrics file not found: {METRICS_FILE}\")\n",
    "    print(\"Run the evaluation script first:\")\n",
    "    print(f\"python scripts/evaluate.py --config {CONFIG_PATH} --checkpoint {CHECKPOINT_PATH} --generate-report\")\n",
    "    per_patient_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ae7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics distribution analysis\n",
    "if per_patient_df is not None:\n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(per_patient_df.describe())\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    metrics = list(per_patient_df.columns)\n",
    "    for i, metric in enumerate(metrics[:6]):  # Plot first 6 metrics\n",
    "        if i < len(axes):\n",
    "            axes[i].hist(per_patient_df[metric], bins=20, alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'{metric.replace(\"_\", \" \").title()} Distribution')\n",
    "            axes[i].set_xlabel('Score')\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            \n",
    "            # Add mean line\n",
    "            mean_val = per_patient_df[metric].mean()\n",
    "            axes[i].axvline(mean_val, color='red', linestyle='--', \n",
    "                          label=f'Mean: {mean_val:.3f}')\n",
    "            axes[i].legend()\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(metrics), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best and worst performing cases\n",
    "if per_patient_df is not None:\n",
    "    # Sort by Dice score\n",
    "    if 'dice' in per_patient_df.columns:\n",
    "        sorted_df = per_patient_df.sort_values('dice', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 5 Best Performing Cases:\")\n",
    "        print(sorted_df.head())\n",
    "        \n",
    "        print(\"\\nTop 5 Worst Performing Cases:\")\n",
    "        print(sorted_df.tail())\n",
    "        \n",
    "        # Correlation analysis\n",
    "        print(\"\\nMetric Correlations:\")\n",
    "        correlation_matrix = per_patient_df.corr()\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.3f')\n",
    "        plt.title('Metric Correlations')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1d57f",
   "metadata": {},
   "source": [
    "## 3. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "if per_patient_df is not None and 'dice' in per_patient_df.columns:\n",
    "    dice_scores = per_patient_df['dice']\n",
    "    \n",
    "    # Performance categories\n",
    "    excellent = (dice_scores >= 0.8).sum()\n",
    "    good = ((dice_scores >= 0.7) & (dice_scores < 0.8)).sum()\n",
    "    fair = ((dice_scores >= 0.5) & (dice_scores < 0.7)).sum()\n",
    "    poor = (dice_scores < 0.5).sum()\n",
    "    \n",
    "    print(f\"\\nPerformance Categories (Dice Score):\")\n",
    "    print(f\"  Excellent (≥0.8): {excellent} cases ({excellent/len(dice_scores)*100:.1f}%)\")\n",
    "    print(f\"  Good (0.7-0.8): {good} cases ({good/len(dice_scores)*100:.1f}%)\")\n",
    "    print(f\"  Fair (0.5-0.7): {fair} cases ({fair/len(dice_scores)*100:.1f}%)\")\n",
    "    print(f\"  Poor (<0.5): {poor} cases ({poor/len(dice_scores)*100:.1f}%)\")\n",
    "    \n",
    "    # Visualization\n",
    "    categories = ['Excellent\\n(≥0.8)', 'Good\\n(0.7-0.8)', 'Fair\\n(0.5-0.7)', 'Poor\\n(<0.5)']\n",
    "    counts = [excellent, good, fair, poor]\n",
    "    colors = ['green', 'orange', 'yellow', 'red']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    bars = ax1.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_title('Performance Distribution')\n",
    "    ax1.set_ylabel('Number of Cases')\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{count}\\n({count/len(dice_scores)*100:.1f}%)',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    ax2.pie(counts, labels=categories, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('Performance Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895b31f",
   "metadata": {},
   "source": [
    "## 4. Failure Case Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515898ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify cases that need attention\n",
    "if per_patient_df is not None:\n",
    "    # Cases with low Dice but high precision (missed lesions)\n",
    "    if 'dice' in per_patient_df.columns and 'precision' in per_patient_df.columns:\n",
    "        low_dice_high_precision = per_patient_df[\n",
    "            (per_patient_df['dice'] < 0.6) & (per_patient_df['precision'] > 0.7)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nCases with Low Dice but High Precision (likely missed lesions): {len(low_dice_high_precision)}\")\n",
    "        if len(low_dice_high_precision) > 0:\n",
    "            print(low_dice_high_precision[['dice', 'precision', 'recall']].head())\n",
    "    \n",
    "    # Cases with high Dice but low precision (many false positives)\n",
    "    if 'dice' in per_patient_df.columns and 'precision' in per_patient_df.columns:\n",
    "        low_precision_cases = per_patient_df[\n",
    "            (per_patient_df['dice'] > 0.6) & (per_patient_df['precision'] < 0.6)\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nCases with Low Precision (many false positives): {len(low_precision_cases)}\")\n",
    "        if len(low_precision_cases) > 0:\n",
    "            print(low_precision_cases[['dice', 'precision', 'recall']].head())\n",
    "    \n",
    "    # Scatter plot: Precision vs Recall\n",
    "    if 'precision' in per_patient_df.columns and 'recall' in per_patient_df.columns:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(per_patient_df['precision'], per_patient_df['recall'], \n",
    "                            c=per_patient_df['dice'], cmap='viridis', alpha=0.7, s=60)\n",
    "        plt.colorbar(scatter, label='Dice Score')\n",
    "        plt.xlabel('Precision')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.title('Precision vs Recall (colored by Dice Score)')\n",
    "        \n",
    "        # Add diagonal line (equal precision and recall)\n",
    "        plt.plot([0, 1], [0, 1], 'r--', alpha=0.5, label='Precision = Recall')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac91e1",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57844340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for analysis\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model_config = config.get('model')\n",
    "model = create_model(\n",
    "    architecture=model_config['architecture'],\n",
    "    **model_config.get('params', {})\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nModel Architecture: {model_config['architecture']}\")\n",
    "print(f\"Input channels: {model_config['params']['in_channels']}\")\n",
    "print(f\"Output channels: {model_config['params']['out_channels']}\")\n",
    "print(f\"Feature size: {model_config['params']['feature_size']}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size (MB): {total_params * 4 / 1024 / 1024:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c11187",
   "metadata": {},
   "source": [
    "## 6. Training Configuration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3aa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training configuration\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {config.get('training.epochs')}\")\n",
    "print(f\"  Batch size: {config.get('data.batch_size')}\")\n",
    "print(f\"  Learning rate: {config.get('optimizer.learning_rate')}\")\n",
    "print(f\"  Weight decay: {config.get('optimizer.weight_decay')}\")\n",
    "print(f\"  Use AMP: {config.get('training.use_amp')}\")\n",
    "\n",
    "print(\"\\nLoss Configuration:\")\n",
    "loss_config = config.get('loss')\n",
    "print(f\"  Type: {loss_config['type']}\")\n",
    "if 'params' in loss_config:\n",
    "    for key, value in loss_config['params'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nData Configuration:\")\n",
    "data_config = config.get('data')\n",
    "print(f\"  Modalities: {data_config['modalities']}\")\n",
    "print(f\"  Target: {data_config['target']}\")\n",
    "print(f\"  Num workers: {data_config['num_workers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb7f6f",
   "metadata": {},
   "source": [
    "## 7. Recommendations for Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00470d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations based on analysis\n",
    "recommendations = []\n",
    "\n",
    "if per_patient_df is not None and 'dice' in per_patient_df.columns:\n",
    "    mean_dice = per_patient_df['dice'].mean()\n",
    "    std_dice = per_patient_df['dice'].std()\n",
    "    \n",
    "    print(f\"\\nModel Performance Analysis:\")\n",
    "    print(f\"Mean Dice Score: {mean_dice:.3f} ± {std_dice:.3f}\")\n",
    "    \n",
    "    if mean_dice < 0.6:\n",
    "        recommendations.append(\"🔴 LOW PERFORMANCE: Consider major changes:\")\n",
    "        recommendations.append(\"   - Review data quality and preprocessing\")\n",
    "        recommendations.append(\"   - Increase model capacity (feature_size: 96 or 128)\")\n",
    "        recommendations.append(\"   - Try different architecture (UNETR, SegResNet)\")\n",
    "        recommendations.append(\"   - Increase training duration (50+ epochs)\")\n",
    "    elif mean_dice < 0.75:\n",
    "        recommendations.append(\"🟡 MODERATE PERFORMANCE: Consider improvements:\")\n",
    "        recommendations.append(\"   - Enhance data augmentation\")\n",
    "        recommendations.append(\"   - Fine-tune loss function weights\")\n",
    "        recommendations.append(\"   - Implement ensemble methods\")\n",
    "        recommendations.append(\"   - Add boundary loss component\")\n",
    "    else:\n",
    "        recommendations.append(\"🟢 GOOD PERFORMANCE: Fine-tuning options:\")\n",
    "        recommendations.append(\"   - Implement test-time augmentation\")\n",
    "        recommendations.append(\"   - Try ensemble of multiple models\")\n",
    "        recommendations.append(\"   - Focus on edge case improvements\")\n",
    "    \n",
    "    # Variability analysis\n",
    "    if std_dice > 0.2:\n",
    "        recommendations.append(\"\\n⚠️  HIGH VARIABILITY detected:\")\n",
    "        recommendations.append(\"   - Review data consistency\")\n",
    "        recommendations.append(\"   - Implement stratified training\")\n",
    "        recommendations.append(\"   - Consider patient-specific normalization\")\n",
    "    \n",
    "    # Precision/Recall analysis\n",
    "    if 'precision' in per_patient_df.columns and 'recall' in per_patient_df.columns:\n",
    "        mean_precision = per_patient_df['precision'].mean()\n",
    "        mean_recall = per_patient_df['recall'].mean()\n",
    "        \n",
    "        if mean_precision < 0.7:\n",
    "            recommendations.append(\"\\n🔸 LOW PRECISION (many false positives):\")\n",
    "            recommendations.append(\"   - Increase focal loss weight\")\n",
    "            recommendations.append(\"   - Add false positive penalty\")\n",
    "            recommendations.append(\"   - Implement post-processing filters\")\n",
    "        \n",
    "        if mean_recall < 0.7:\n",
    "            recommendations.append(\"\\n🔸 LOW RECALL (missing lesions):\")\n",
    "            recommendations.append(\"   - Increase Dice loss weight\")\n",
    "            recommendations.append(\"   - Review data augmentation\")\n",
    "            recommendations.append(\"   - Consider multi-scale training\")\n",
    "\n",
    "# Training efficiency recommendations\n",
    "batch_size = config.get('data.batch_size')\n",
    "if batch_size == 1:\n",
    "    recommendations.append(\"\\n⚡ TRAINING EFFICIENCY:\")\n",
    "    recommendations.append(\"   - Consider gradient accumulation for larger effective batch size\")\n",
    "    recommendations.append(\"   - Try mixed precision training if not already enabled\")\n",
    "    recommendations.append(\"   - Implement learning rate warmup\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDATIONS FOR IMPROVEMENT\")\n",
    "print(\"=\"*60)\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Run comprehensive evaluation:\")\n",
    "print(f\"   python scripts/evaluate.py --config {CONFIG_PATH} --checkpoint {CHECKPOINT_PATH} --generate-report\")\n",
    "print(\"\\n2. Generate visualizations:\")\n",
    "print(\"   python scripts/visualize_results.py --predictions-dir /path/to/predictions --ground-truth-dir /path/to/gt --images-dir /path/to/images --output-dir visualizations\")\n",
    "print(\"\\n3. Consider training improvements and run next iteration\")\n",
    "print(\"\\n4. Review failure cases manually for data quality issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45713426",
   "metadata": {},
   "source": [
    "## 8. Next Training Configuration Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate improved configuration template\n",
    "improved_config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"swinunetr\",\n",
    "        \"params\": {\n",
    "            \"in_channels\": 4,\n",
    "            \"out_channels\": 1,\n",
    "            \"feature_size\": 96,  # Increased from 48\n",
    "            \"drop_rate\": 0.1,    # Added dropout\n",
    "            \"attn_drop_rate\": 0.1,\n",
    "            \"dropout_path_rate\": 0.1,\n",
    "            \"use_checkpoint\": True,\n",
    "            \"use_deep_supervision\": True\n",
    "        }\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"type\": \"combo\",\n",
    "        \"params\": {\n",
    "            \"dice_weight\": 1.0,\n",
    "            \"focal_weight\": 1.0,  # Increased if precision issues\n",
    "            \"focal_gamma\": 2.0,\n",
    "            \"include_background\": False\n",
    "        }\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"adamw\",\n",
    "        \"learning_rate\": 1e-4,  # Slightly higher\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    \"scheduler\": {\n",
    "        \"use_scheduler\": True,\n",
    "        \"type\": \"cosine_warmup\",\n",
    "        \"params\": {\n",
    "            \"warmup_epochs\": 20,  # Longer warmup\n",
    "            \"min_lr\": 1e-7\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 100,  # More epochs\n",
    "        \"use_amp\": True,\n",
    "        \"grad_clip\": 1.0,\n",
    "        \"val_interval\": 1\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"batch_size\": 2,  # Try to increase if possible\n",
    "        \"augmentation\": {\n",
    "            \"rotation\": [-15, 15],\n",
    "            \"scaling\": [0.9, 1.1],\n",
    "            \"elastic_deformation\": True,\n",
    "            \"gaussian_noise\": 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Suggested Configuration Improvements:\")\n",
    "print(\"\\n# Enhanced SwinUNETR Configuration\")\n",
    "print(\"# Based on current model analysis\")\n",
    "print(\"\\n# Key changes:\")\n",
    "print(\"# - Increased feature_size for more capacity\")\n",
    "print(\"# - Added dropout for regularization\")\n",
    "print(\"# - Adjusted learning rate and warmup\")\n",
    "print(\"# - Extended training duration\")\n",
    "print(\"# - Enhanced data augmentation\")\n",
    "\n",
    "import yaml\n",
    "print(\"\\n\", yaml.dump(improved_config, default_flow_style=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
