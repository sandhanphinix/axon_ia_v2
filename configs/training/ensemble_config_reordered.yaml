# Ensemble Training Configuration for Medical Image Segmentation
# Optimized for small lesion detection with 5 state-of-the-art models
# REORDERED: Testing uncertain models first, SwinUNETR last

# Global settings
global:
  experiment_name: "ensemble_v2_small_lesions"
  output_dir: "C:/development/data/axon_ia/outputs/ensemble_v2"
  use_validation_split: false  # Disabled because we're using k-fold CV
  seed: 41
  
  # 5-fold cross-validation
  cross_validation:
    enabled: true
    n_folds: 5
    stratified: true
    random_state: 41
  
  # Enhanced data augmentation for small lesion detection
  augmentation:
    spatial:
      rotation_range: [-15, 15]
      scaling_range: [0.85, 1.15]
      shearing_range: [-5, 5]
      translation_range: [-10, 10]
    
    intensity:
      brightness_range: [-0.15, 0.15]
      contrast_range: [0.85, 1.15]
      gamma_range: [0.8, 1.2]
      gaussian_noise_std: 0.08
      gaussian_blur_sigma: [0.5, 1.0]
    
    geometric:
      elastic_deformation: true
      flip_probability: 0.5
      crop_foreground: true
    
    advanced:
      mixup_alpha: 0.2
      cutmix_alpha: 1.0
      mosaic_probability: 0.1
      copy_paste_probability: 0.05

  # Training parameters - Optimized for RTX 4080 + 64GB RAM
  training:
    max_epochs: 200                 # Increased for better convergence
    early_stopping_patience: 50     # Increased patience for thorough training
    batch_size: 8                   # Significantly increased for GPU
    accumulate_grad_batches: 1      # No need to accumulate with larger batch size
    precision: "16-mixed"           # Mixed precision for faster training
    num_workers: 8                  # Utilize more CPU cores
    pin_memory: true                # Enable for GPU training
    device: "cuda"                  # Use GPU
    
    # Curriculum learning - Enhanced for better training
    curriculum_learning:
      enabled: true   
      warmup_epochs: 30             # Increased warmup for better stability
      easy_samples_ratio: 0.7       # Start with more easy samples
      difficulty_metric: "lesion_volume"
    
    # Class balancing for small lesions - Enhanced
    class_balancing:
      enabled: true   
      small_lesion_threshold: 100   # Lower threshold for better small lesion detection
      small_lesion_boost: 4.0       # Increased boost for small lesions
      hard_negative_mining: true    # Enable with more memory available

# Model configurations - REORDERED TO TEST FIXES FIRST
models:
  # Model 1: UNETR - Fixed version with improved parameters (TEST FIRST)
  unetr_compact:
    architecture: "unetr"
    params:
      img_size: [128, 128, 128]     # Increased to 128³ for better detail capture
      in_channels: 4
      out_channels: 1
      feature_size: 32              # Increased for better performance  
      hidden_size: 516              # Increased for better capacity (divisible by 6 for pos embedding)
      mlp_dim: 2064                 # Increased proportionally (516 * 4) 
      num_heads: 16                 # Increased number of attention heads
      patch_size: 16                # 128/16 = 8, so 8³ = 512 patches
      pos_embed: "learnable"        # Use learnable embeddings
      norm_name: "instance"
      conv_block: true
      res_block: true
      dropout_rate: 0.1             # Add some dropout for regularization
      use_deep_supervision: true    # Re-enable for better learning
    
    loss:
      type: "combo_loss_v2"        # Consistent loss function
      params:
        dice_weight: 1.0
        focal_weight: 0.5
        focal_gamma: 2.0
        boundary_weight: 0.1      # Small boundary loss for edge detection
    
    optimizer:
      type: "adamw"
      learning_rate: 5e-5           # Increased learning rate for faster convergence
      weight_decay: 0.01            
      betas: [0.9, 0.95]
    
    scheduler:
      type: "cosine_warmup"
      params:
        warmup_epochs: 30           # Match curriculum learning warmup
        min_lr: 1e-6
        max_lr: 5e-5

  # Model 2: SegResNet - Robust configuration to prevent failures
  segresnet_compact:
    architecture: "segresnet"
    params:
      spatial_dims: 3
      init_filters: 32              # Increased for better performance
      in_channels: 4
      out_channels: 1
      dropout_prob: 0.1             # Increased dropout for regularization
      blocks_down: [2, 3, 4, 4]     # Increased depth for better feature extraction
      blocks_up: [2, 2, 2, 2]       # Matched upsampling stages
      norm: "batch"                 # Switch to batch norm for GPU training
      use_conv_final: true
      deep_supervision: true        # Re-enable for better learning
    
    loss:
      type: "combo_loss_v2"
      params:
        dice_weight: 1.0
        focal_weight: 0.3         # Reduced focal weight for stability
        focal_gamma: 2.0
        boundary_weight: 0.0
    
    optimizer:
      type: "adamw"               
      learning_rate: 2e-4           # Increased learning rate
      weight_decay: 0.01
      betas: [0.9, 0.999]
    
    scheduler:
      type: "cosine_warmup"
      params:
        warmup_epochs: 30           # Match curriculum learning
        min_lr: 1e-6
        max_lr: 2e-4

  # Model 3: Custom ResUNet - Robust configuration for stability
  resunet_compact:
    architecture: "residual_unet"
    params:
      in_channels: 4
      out_channels: 1
      features: [32, 64, 128, 256, 512]  # Increased capacity for better performance
      dropout: 0.1                      # Increased dropout for regularization
      attention_gates: true             # Keep attention gates for performance
      deep_supervision: true            # Re-enable for better learning
      residual_connections: true
      squeeze_excitation: true          # Re-enable with more GPU memory
    
    loss:
      type: "combo_loss_v2"
      params:
        dice_weight: 1.0
        focal_weight: 0.3           # Reduced for stability
        focal_gamma: 2.0
        boundary_weight: 0.0
    
    optimizer:
      type: "adamw"                   
      learning_rate: 2e-4             # Increased learning rate
      weight_decay: 0.01
      betas: [0.9, 0.999]
    
    scheduler:
      type: "cosine_warmup"
      params:
        warmup_epochs: 30             # Match curriculum learning
        min_lr: 1e-6
        max_lr: 2e-4

  # Model 4: Multi-Scale UNet - Simplified for robustness and CPU compatibility
  multiscale_compact:
    architecture: "multiscale_unet"
    params:
      in_channels: 4
      out_channels: 1
      base_features: 32               # Increased for better performance
      growth_rate: 16                 # Increased for better feature extraction
      num_layers: [3, 4, 6, 8]        # Increased depth for better learning
      dropout: 0.1                    # Increased dropout for regularization
      multiscale_features: true       # Re-enable with more GPU memory
      dense_connections: true         # Keep for gradient flow
      deep_supervision: true          # Re-enable for better learning
      pyramid_pooling: true           # Re-enable with more memory
    
    loss:
      type: "combo_loss_v2"
      params:
        dice_weight: 1.0
        focal_weight: 0.3           # Reduced for stability
        focal_gamma: 2.0
        boundary_weight: 0.0
    
    optimizer:
      type: "adamw"
      learning_rate: 2e-4           # Increased learning rate
      weight_decay: 0.01
      betas: [0.9, 0.999]
    
    scheduler:
      type: "cosine_warmup"
      params:
        warmup_epochs: 30           # Match curriculum learning
        min_lr: 1e-6
        max_lr: 2e-4

  # Model 5: SwinUNETR - SAVE FOR LAST (known working model)
  swinunetr_compact:
    architecture: "swinunetr"
    params:
      img_size: [128, 128, 128]     # Increased to 128³ for better detail
      in_channels: 4
      out_channels: 1
      feature_size: 64              # Increased feature size
      use_checkpoint: true
      spatial_dims: 3
      depths: [2, 2, 6, 2]          # Standard SwinUNETR depths
      num_heads: [3, 6, 12, 24]     # Standard SwinUNETR heads
      window_size: [7, 7, 7]        # Standard window size
      use_deep_supervision: true    # Keep deep supervision for better learning
      drop_rate: 0.1                # Add dropout for regularization
      attn_drop_rate: 0.1           # Add attention dropout
      dropout_path_rate: 0.1        # Add path dropout
    
    # Load pretrained weights from successful model
    pretrained_path: "C:/development/data/axon_ia/outputs/swinunetr/checkpoints/model_015.pth"
    
    loss:
      type: "combo_loss_v2"        # Use combo loss like successful config
      params:
        dice_weight: 1.0          # Match successful config
        focal_weight: 0.5         # Match successful config
        focal_gamma: 2.0          # Match successful config
        boundary_weight: 0.1      # Add small boundary loss for better edge detection
    
    optimizer:
      type: "adamw"
      learning_rate: 3e-4           # Increased learning rate for SwinUNETR
      weight_decay: 0.01            
      betas: [0.9, 0.999]
    
    scheduler:
      type: "cosine_warmup"
      params:
        warmup_epochs: 30           # Match curriculum learning
        min_lr: 1e-6              
        max_lr: 3e-4              # Match increased learning rate

# Ensemble configuration - Simplified
ensemble:
  voting_strategy: "soft"  # soft, hard, weighted
  weights: "adaptive"  # equal, adaptive, learned
  test_time_augmentation:
    enabled: true
    n_tta: 8                    # Increased TTA for better performance
    tta_types: ["flip", "rotate", "scale"]  # More augmentation types
  
  # Multi-scale testing - Re-enabled with GPU power
  multi_scale_testing:
    enabled: true               # Re-enabled for better performance
    scales: [0.85, 1.0, 1.15]   # Multiple scales for better detection
  
  # Post-processing - Enhanced
  post_processing:
    remove_small_objects: true
    min_object_size: 3          # Reduced for better small lesion detection
    fill_holes: true            # Re-enabled
    morphological_closing: true # Re-enabled

# Data configuration - Heavily CPU optimized
data:
  # Actual directory structure:
  # dataset_path/
  #   ├── train/         # 334 patient folders
  #   │   ├── 001/
  #   │   │   ├── b0_001.nii.gz           # Training images
  #   │   │   ├── b1000_001.nii.gz
  #   │   │   ├── flair_001.nii.gz
  #   │   │   ├── T2Star_001.nii.gz
  #   │   │   ├── perfroi_001.nii.gz      # Target: brain lesions
  #   │   │   └── eloquentareas_001.nii.gz # Target: eloquent areas
  #   │   ├── 002/
  #   │   │   ├── b0_002.nii.gz
  #   │   │   └── ...
  #   │   └── ...
  #   └── test/          # 109 patient folders
  #       └── ...
  dataset_path: "C:/development/data/axon_ia"
  
  # Modality configuration
  modalities: ["b0", "b1000", "flair", "T2Star"]  # Training images
  target: "perfroi"  # Default target for brain lesion segmentation
  # Alternative target: "eloquentareas" for eloquent area segmentation
  
  cache_rate: 0.3      # Enable caching with more RAM
  num_workers: 8       # Increased workers for faster data loading
  pin_memory: true     # Enable for GPU training
  
  # Preprocessing - Enhanced for better performance
  preprocessing:
    normalize_intensity: true
    clip_intensity: [-3, 3]        
    resample_spacing: [1.0, 1.0, 1.0]  # Higher resolution for better detail
    roi_size: [128, 128, 128]           # Match increased image size
    normalize_mode: "z_score"       
    
  # Advanced sampling - Enhanced
  sampling:
    foreground_ratio: 0.8           # Increased foreground sampling
    uniform_sampling: false
    weighted_sampling: true
    small_lesion_boost: 3.0         # Increased boost for small lesions

# Logging and monitoring
logging:
  wandb:
    enabled: false
    project: "axon_ia_ensemble"
    tags: ["ensemble", "small_lesions", "5fold_cv"]
  
  tensorboard:
    enabled: true
    log_dir: "logs/ensemble_v2"
  
  checkpointing:
    save_top_k: 3
    monitor: "val_dice"
    mode: "max"
    save_last: true

# Hardware configuration - Optimized for RTX 4080 + 64GB RAM
hardware:
  gpus: 1              # Use 1 GPU (RTX 4080)
  device: "cuda"       # Use CUDA
  precision: "16-mixed" # Mixed precision for faster training
  mixed_precision: true # Enable mixed precision
  num_workers: 8       # Utilize more CPU cores
  pin_memory: true     # Enable for GPU training
  strategy: "auto"
  sync_batchnorm: true # Enable sync batch norm for better training
